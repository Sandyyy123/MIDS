{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Final: Santander Customer Satisfaction\n",
    "### DATASCI W207 - Nilesh Bhoyar & Greg Ceccarelli "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "For our final we've chosen the Santander customer satisifcation kaggle challenge. \n",
    "https://www.kaggle.com/c/santander-customer-satisfaction\n",
    "\n",
    "Santander Bank is asking Kagglers to help them identify dissatisfied customers early in their relationship. Doing so would allow Santander to take proactive steps to improve a customer's happiness before it's too late.\n",
    "\n",
    "The challenge for us is to work with a dataset consisting of hundreds of annoynimized features to predict customer satisfaction for their customers\n",
    "\n",
    "## Relevant Links\n",
    "\n",
    "* [Course Final Project plan](https://goo.gl/S2Qn0Z)\n",
    "* [Dataset Dictionary Thread](https://www.kaggle.com/c/santander-customer-satisfaction/forums/t/19291/data-dictionary)\n",
    "* [Spanish2English Translation](https://www.kaggle.com/blobs/download/forum-message-attachment-files/3832/Spanish2English.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "#import regularization\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#import other libraries to help download data\n",
    "import urllib2\n",
    "import os\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is /Users/gregce/MIDS/DATASCI_W207/Assignments/kaggle\n"
     ]
    }
   ],
   "source": [
    "#check current dir is right and then download the data into it\n",
    "cwd = os.getcwd()\n",
    "# newdir = cwd +\"\\\\test\"\n",
    "print \"The current working directory is \" + cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data. We also are going to split the data into two sets, training and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## use pandas to load the training data into memory\n",
    "all_train = pd.read_csv(\"../kaggle/data/train 2.csv\")\n",
    "train_labels = list(all_train.columns.values)\n",
    "# all_train.shape()\n",
    "\n",
    "train_labels.remove('TARGET')\n",
    "Y, X = all_train.TARGET, all_train[train_labels]\n",
    "## make sure these are numpy arrays\n",
    "Y, X = Y.values, X.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_test = pd.read_csv(\"../kaggle/data/test.csv\")\n",
    "test_labels = list(all_test.columns.values)\n",
    "test_data = all_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 370)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Didn't run the following three cells ATM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print 'data shape: ', X.shape\n",
    "print 'label shape:', Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set some variables to hold test, dev, and training data.\n",
    "test_data, test_labels = X[61000:], Y[61000:]\n",
    "dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n",
    "train_data, train_labels = X[:60000], Y[:60000]\n",
    "mini_train_data, mini_train_labels = X[:1000], Y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Try Penalized Regression, l1\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def line(length=80):\n",
    "    line = \"-\"\n",
    "    return(line * length + '\\n')\n",
    "\n",
    "#define quick wrapper function\n",
    "def gridsearch(classifier, param_grid, data, labels, scoring='roc_auc'):\n",
    "    gs = GridSearchCV(classifier, param_grid, scoring)\n",
    "    gs.fit(data, labels)\n",
    "    return([gs.best_params_, gs.best_score_])\n",
    "\n",
    "#define grid search parameters\n",
    "plr_param = {'C': np.arange(0.001, .5, 0.001)}\n",
    "knn_param = {'n_neighbors': range(1,10)}\n",
    "\n",
    "\n",
    "#search for optimal parameters\n",
    "# print \"Try KNN\"\n",
    "# print line()\n",
    "# knn = gridsearch(KNeighborsClassifier(), knn_param, X, Y)\n",
    "# print \"Best: %s with accuracy %.4f\" % (knn[0], knn[1])\n",
    "\n",
    "print \"\\n Try Penalized Regression, l1\"\n",
    "print line()\n",
    "plr = gridsearch(LogisticRegression(penalty='l1'), plr_param, X, Y)\n",
    "print \"Best: %s with accuracy %.4f\" % (plr[0], plr[1])\n",
    "print \"\\n\"\n",
    "\n",
    "print \"\\n Try Penalized Regression, l2\"\n",
    "print line()\n",
    "plr = gridsearch(LogisticRegression(penalty='l2'), plr_param, X, Y)\n",
    "print \"Best: %s with accuracy %.4f\" % (plr[0], plr[1])\n",
    "print \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregce/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## fit a model using l1 penalized regression\n",
    "## given the extreme class imbalance [3% positive in the training data, use class_weight=\"auto\"]\n",
    "model = LogisticRegression(penalty='l1', C=.155, class_weight=\"auto\")\n",
    "model.fit(X, Y)\n",
    "predict = model.predict(test_data)\n",
    "\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(test_labels, predict)\n",
    "# metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save output\n",
    "pred_df = pd.DataFrame(predict)\n",
    "#make sure to set the id column back to the ID from the TEST data\n",
    "#not just the ID of the row index...\n",
    "pred_df['ID'] = all_test['ID']\n",
    "pred_df.columns = ['TARGET','ID']\n",
    "pred_df = pred_df[['ID','TARGET']]\n",
    "pred_df.to_string(index=False)\n",
    "\n",
    "pred_df.to_csv(\"gc_submission1.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
