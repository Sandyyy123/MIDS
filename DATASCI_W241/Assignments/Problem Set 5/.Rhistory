## fill yes/no function
yesNo <- function(N, pct) {
k <- round(N * pct, 0)
k1 <- N - k
c(rep(1, k), rep(0, k1))
View(d)
View(d)
colnames(df) <- c("pvalue","pass")
;
;;;;
fafa
;
21341+222
;
();
rm(list<-ls())
rm(listls())
rm( list = ls() )
d <- data.frame(running = runif(1000, min = 0, max = 10),
cov1    = rnorm(1000))
install.packages(c("ggplot2"))
View(d)
d$y <- d$running * .5 - .2 * d$cov1 + 1 * I(d$running > 5) + rnorm(1000)
d$y <- d$running * .5 - .2 * d$cov1 + 1 * I(d$running > 5) + rnorm(1000)
View(d)
hist(d$y)
plot(x = d$running, y = d$y, pch = 19, col = rgb(0,1,0, .4), ylim = c(-2, 10))
lines(lowess(x = , y = ))
lines(lowess(x = , y = ))
lines(lowess(x = d$running , y = d$y ))
install.packages(c("stargazer"))
install.packages(c("bestGLM"))
install.packages(c("bestglm"))
?lowess
library(dplyr)
cuttoff <- 5
plot(x = , y = , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
View(d)
View(d)
View(d)
d_lower <- d %>%
filter(running < cutoff)
View(d)
d$cutoff <- 5
d_lower <- d %>%
filter(running < cutoff)
d_higher <- d %>%
filter(running > cutoff)
plot(x = d$running , y = d$y , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
plot(x = d$running , y = d$y , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
lines(lowess(x = d_lower$running , y = d_lower$y ), lwd = 2) # lower than cuttoff
lines(lowess(x = d_higher$running, y = d_higher$y), lwd = 2) # higher than cuttoff
d$cutoff <- 3
d_lower <- d %>%
filter(running < cutoff)
d_higher <- d %>%
filter(running > cutoff)
plot(x = d$running , y = d$y , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
lines(lowess(x = d_lower$running, y = d_lower$y ), lwd = 2) # lower than cuttoff
lines(lowess(x = d_higher$running, y = d_higher$y), lwd = 2) # higher than cuttoff
for(i in 1:9) {
d$cutoff <- i
d_lower <- d %>%
filter(running < cutoff)
d_higher <- d %>%
filter(running > cutoff)
plot(x = d$running , y = d$y , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
lines(lowess(x = d_lower$running, y = d_lower$y ), lwd = 2) # lower than cuttoff
lines(lowess(x = d_higher$running, y = d_higher$y), lwd = 2) # higher than cuttoff
}
for(i in 1:9) {
d$cutoff <- i
d_lower <- d %>%
filter(running < cutoff)
d_higher <- d %>%
filter(running > cutoff)
plot(x = d$running , y = d$y , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
lines(lowess(x = d_lower$running, y = d_lower$y ), lwd = 2) # lower than cuttoff
lines(lowess(x = d_higher$running, y = d_higher$y), lwd = 2) # higher than cuttoff
}
install.packages("rdrobust")
library(rdrobust)
data(rdrobust_RDsenate)
d2 <- rdrobust_RDsenate
with(d2, rdplot(y = vote, x = margin,
title = "RD Plot - Senate Elections Data",
y.label = "Vote Share in Election at time t+1",
x.label = "Vote Share in Election at time t") )
R.version()
R.version
setwd("MIDS/DATASCI_W241/Assignments/Project/")
## Load relevant libraries
##############################
## Setup
##############################
## Clear environment variables
rm( list = ls())
## Set Working Directory
setwd("MIDS/DATASCI_W241/Assignments/Project/")
## Load relevant libraries
library(pryr)
library(memisc)
library(stringr)
library(stargazer)
library(dplyr)
library(ggplot2)
library(data.table)
library(lubridate)
library(RDSTK)
## Define Relevant Functions
coalesce2 <- function(...) {
Reduce(function(x, y) {
i <- which(is.na(x))
x[i] <- y[i]
x},
list(...))
}
##############################
## Data Processing
##############################
## Read in Data
pd.raw <- read.csv("Full Data Collection - Cleaned.csv", header=TRUE, stringsAsFactors=FALSE
, fileEncoding="latin1", na.strings=c("","NA"))
#remove dups
by_ips <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
select(V6) %>%
mutate(ip=V6) %>%
group_by(V6) %>%
summarise(bpcnt = count(ip))
duplicate_ips <- data.frame(by_ips$bpcnt$x, by_ips$bpcnt$freq)
names(duplicate_ips) <- c("x","freq")
duplicate_ips <- duplicate_ips %>%
filter(freq>1)
#recreate with dups removed
pd.raw <- pd.raw %>%
filter(!(V6 %in% duplicate_ips$x))
## General Information DF
pd.gen <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
##leverage lubridate mdy_hm to convert to dates
mutate(  gen_StartDate = mdy_hm(V8)
, gen_EndDate = mdy_hm(V9)
, gen_TotalTimeSpentMinutes = gen_EndDate - gen_StartDate
##leverage cases function from memiscv for label assignment
, gen_Gender = cases("Male"=Q7==1,
"Female"=Q7==2,
"Prefer not to respond"=Q7==3)
, gen_Age = as.numeric(Q5)+14
, gen_Education = cases("Less than High School"=Q2==1,
"High School / GED"=Q2==2,
"Some College"=Q2==3,
"2-year College Degree"=Q2==4,
"4-year College Degree"=Q2==5,
"Masters Degree"=Q2==6,
"Doctoral Degree"=Q2==7,
"Professional Degree (JD, MD)"=Q2==8)
, gen_Role = cases("Owner / Founder"=Q53==1,
"Executive Officer"=Q53==2,
"Director"=Q53==3,
"Manager"=Q53==4,
"Employee"=Q53==5,
"None of these apply"=Q53==6
)
, gen_Industry = cases("Construction"=Q10==1,
"Education"=Q10==2,
"Financial Activities"=Q10==3,
"Health Care or Pharmecuticals"=Q10==4,
"Information"=Q10==5,
"Leisure and Hospitality"=Q10==6,
"Manufacturing"=Q10==7,
"Natural Resources and Mining"=Q10==8,
"Professional and Business Services"=Q10==9,
"Trade, Transportation and Utilites"=Q10==10,
"None of these apply"=Q10==11)
#, gen_State = as.vector(fromJSON(coordinates2politics(LocationLatitude, LocationLongitude))))$politics.name.1)
, gen_PageOneTimeMinutes = (as.numeric(Q56_2)-as.numeric(Q56_1))/60
#, gen_PageOneTimePercentOfTotal = as.numeric(gen_PageOneTimeMinutes)/as.numeric(gen_TotalTimeSpentMinutes)*100
, gen_PageOneNumberClicks = as.numeric(Q56_4)
) %>%
#Only keep observations that finished
filter(V10==1) %>%
##only retain IPAddress & "gen_" columns
select(IPAddress = V6, starts_with("gen_"))
## IQ Test Information DF
pd.iq <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(  iq_Question1Response = Q25
, iq_Question1CorrectAnswer = ifelse(Q25==1,1,0)
, iq_Question2Response = Q59
, iq_Question2CorrectAnswer = ifelse(Q59==4,1,0)
, iq_Question3Response = Q27
, iq_Question3CorrectAnswer = ifelse(Q27==2,1,0)
, iq_TotalCorrect = iq_Question1CorrectAnswer+iq_Question2CorrectAnswer+iq_Question3CorrectAnswer
, iq_PercentageCorrect = iq_TotalCorrect/3
, iq_PageTwoTimeMinutes = (as.numeric(Q57_2)-as.numeric(Q57_1))/60
, iq_PageTwoNumberClicks = as.numeric(Q57_4)) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("iq_"))
## Experiment 1 Information DF
pd.exp1 <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(  temp_Treat1 = ifelse(Q19==1,"Nonordered chart junk",NA)
,temp_Treat2 = ifelse(Q20==1,"Nonordered table",NA)
,temp_Treat3 = ifelse(Q21==1,"Nonordered tufte",NA)
,temp_Treat4 = ifelse(Q23==1,"Ordered chart junk",NA)
,temp_Treat5 = ifelse(Q24==1,"Ordered Table",NA)
,temp_Treat6 = ifelse(Q25.1==1,"Ordered tufte",NA)
##use coalesce function to get everything in a single column
,exp1_Treatment = coalesce2(temp_Treat1,temp_Treat2,temp_Treat3,temp_Treat4,temp_Treat5,temp_Treat6)
,exp1_Question1Response = Q27.1
,exp1_Question1CorrectAnswer = ifelse(Q27.1==3,1,0)
,exp1_Question2Response = Q29
,exp1_Question2CorrectAnswer = ifelse(Q29==3,1,0)
,exp1_Question3Response = Q28
,exp1_Question3CorrectAnswer = ifelse(Q28==3,1,0)
,exp1_Question4Response = Q29
,exp1_Question4CorrectAnswer = ifelse(Q29==1,1,0)
,exp1_TotalCorrect = exp1_Question1CorrectAnswer+exp1_Question2CorrectAnswer+exp1_Question3CorrectAnswer+exp1_Question4CorrectAnswer
,exp1_PercentageCorrect = exp1_TotalCorrect/4
,exp1_Question5Response = Q30
,exp1_PageThreeTimeMinutes = (as.numeric(Q20_2)-as.numeric(Q20_1))/60
,exp1_PageThreeNumberClicks = as.numeric(Q20_4)
##added this since pages were split up
,exp1_PageFourTimeMinutes = (as.numeric(Q71_2)-as.numeric(Q71_1))/60
,exp1_PageFourNumberClicks = as.numeric(Q71_4)
) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("exp1_"))
## Recall Information DF
## Could include Treatment but this can be joined on if necessary
pd.recall <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(    recall_Question1Response = Q31
,recall_Question1CorrectAnswer = ifelse(Q31==6,1,0)
,recall_Question2Response = Q32
,recall_Question2CorrectAnswer = ifelse(Q32==6,1,0)
,recall_Invalid = ifelse(!Q63==3,1,0)
,recall_TotalCorrect = recall_Question1CorrectAnswer+recall_Question2CorrectAnswer
,recall_PercentageCorrect = recall_TotalCorrect/2
,recall_PageFiveTimeMinutes = (as.numeric(Q34_2)-as.numeric(Q34_1))/60
,recall_PageFiveNumberClicks = as.numeric(Q34_4)) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("recall_"))
## Experiment 2 Information DF
pd.exp2 <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(  temp_Treat1 = ifelse(Q40==1,"Log scatterplot",NA)
,temp_Treat2 = ifelse(Q58==1,"No Log scatterplot",NA)
,temp_Treat3 = ifelse(Q42==1,"Unordered Table",NA)
,temp_Treat4 = ifelse(Q43==1,"Ordered Table",NA)
##use coalesce function to get everything in a single column
,exp2_Treatment = coalesce2(temp_Treat1,temp_Treat2,temp_Treat3,temp_Treat4)
,exp2_DisplayedTreatment = Q76
,exp2_Question1Response = Q35_1
,exp2_Question2Response = Q36
,exp2_Question2CorrectAnswer = ifelse(Q36==1,1,0)
##Should Question 1 have a correct answer??
,exp2_Question3Response = Q61
,exp2_Question3CorrectAnswer = ifelse(Q61==2,1,0)
,exp2_Question4Response = Q62
,exp2_Question4CorrectAnswer = ifelse(Q62==2,1,0)
,exp2_TotalCorrect = #exp2_Question1CorrectAnswer+
exp2_Question2CorrectAnswer+exp2_Question3CorrectAnswer+exp2_Question4CorrectAnswer
,exp2_PercentageCorrect = exp2_TotalCorrect/3
,exp2_PageSixTimeMinutes = (as.numeric(Q23_2)-as.numeric(Q23_1))/60
,exp2_PageSixNumberClicks = as.numeric(Q23_4)
,exp2_PageSevenTimeMinutes = (as.numeric(Q79_2)-as.numeric(Q79_1))/60
,exp2_PageSevenNumberClicks = as.numeric(Q79_4)
) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("exp2_"))
## Final Questions Information DF
pd.fq <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(finalq_Question1Response = Q38
,finalq_Question1CorrectAnswer = ifelse(Q38==5,1,0)
,finalq_Question2Response = Q37_1
,finalq_Question3Response = Q37_2
,finalq_PercentageCorrect = finalq_Question1CorrectAnswer
) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("finalq_"))
##############################
## Data Output
##############################
pd.cleaned <- inner_join(pd.gen, pd.iq, by = "IPAddress") %>%
inner_join(pd.exp1, by = "IPAddress") %>%
inner_join(pd.recall, by = "IPAddress") %>%
inner_join(pd.exp2, by = "IPAddress") %>%
inner_join(pd.fq, by = "IPAddress")
##Update Factors for exp1_Treatment
pd.cleaned$exp1_Treatment <- factor(pd.cleaned$exp1_Treatment)
pd.cleaned$exp1_Treatment <- factor(pd.cleaned$exp1_Treatment,levels(pd.cleaned$exp1_Treatment)[c(2,1,3,4,5,6)])
## Write Out Data For Easy Import
save(pd.cleaned, file="CourseProjectCleanedData.rda")
write.csv(pd.cleaned, file = "CourseProjectCleanedData.csv",row.names=FALSE, na="")
View(pd.raw)
View(pd.cleaned)
mean(pd.cleaned$gen_TotalTimeSpentMinutes)
rm( list = ls() )
library(data.table)
library(foreign)
library(data.table)
d <- data.frame(running = runif(1000, min = 0, max = 10),
cov1    = rnorm(1000))
d$y <- d$running * 0.1 - .2 * d$cov1 + 1 * I(d$running > 5) + rnorm(1000)
plot(x = d$running, d$y, pch = 19, col = rgb(0,1,0, .4))
lines(lowess(d$running, d$y))
## a)
plot(x = d$running, d$y, pch = 19, col = rgb(0,1,0, .4))
lines(lowess(d$running, d$y))
with(d, plot(running, y, pch = 19, col = rgb(0,0,1, .2)))
lines(lowess(d$running[d$running < 5], d$y[d$running < 5]), lwd = 2)
lines(lowess(d$running[d$running > 5], d$y[d$running > 5]), lwd = 2)
with(d, plot(running, y, pch = 19, col = rgb(1,0,0, .2)))
lines(lowess(d$running[d$running < 3], d$y[d$running < 3]), lwd = 2)
lines(lowess(d$running[d$running > 3], d$y[d$running > 3]), lwd = 2)
for(i in 1:9) {
with(d, plot(running, y, pch = 19, col = rgb(1,0,0, .2)))
lines(lowess(d$running[d$running < i], d$y[d$running < i]), lwd = 2)
lines(lowess(d$running[d$running > i], d$y[d$running > i]), lwd = 2)
}
m1 <- lm(y ~ running, data = d)
m2 <- lm(y ~ running + cov1, data = d)
m3 <- lm(y ~ running + I(running > 5) + cov1, data = d)
summary(m3)
m4 <- lm(y ~ I(running > 5), data = d[d$running > 4.8 & d$running < 5.2, ])
data(rdrobust_RDsenate)
m1 <- d[ , lm(unemployment_duration ~ age + I(age > 50))]
m2 <- d[ , lm(unemployment_duration ~ age + I(age > 50) * female)]
m3 <- d[age > 49 & age < 51 , lm(unemployment_duration ~ age50
+ marr + single + educ_med + educ_hi + foreign + rr
+ lwage_ljob + previous_experience + white_collar
+ landw + versorg + nahrung + textil + holzind
+ elmasch + andfabr + bau + gasthand + verkehr
+ dienstl
+ age) ]
summary(m3)
m1
library(data.table)
library(foreign)
library(stargazer)
library(dplyr)
## data from FEDAI
d <- read.dta("http://hdl.handle.net/10079/0cfxq05")
dt <- data.table(d)
sem <- function(x) sqrt(var(x) / length(x))
dt[ , .(m  = mean(call),
se = sem(call)),
by = c("h","race") ]
d %>%
group_by(h, race) %>%
summarise(m  = mean(call),
se = sem(call))
m <- lm(call ~ h*race, data = dt)
summary(m)
library(data.table)
set.seed(2)
rm( list = ls() )
library(data.table)
set.seed(2)
d <- data.table(gender = sample(c("male", "female"),     100, replace = TRUE),
edu    = sample(c("low", "med", "high"), 100, replace = TRUE),
bum    = sample(c("bum", "notBum"),      100, replace = TRUE),
treat  = sample(c("treat", "control"),   100, replace = TRUE) )
View(d)
d[ , y := 1 + .5 * I(gender == "female") + 2 * I(edu == "high") + 1 * I(edu == "med") + 10 * I(treat == "treat") + rnorm(.N)]
View(d)
d[bum == "bum",    missing := rbinom(n = .N, size = 1, prob = .8)]
d[bum == "notBum", missing := rbinom(n = .N, size = 1, prob = .2)]
View(d)
mean(d[treat == "treat", y]) - mean(d[treat == "control", y])
mean(d[treat == "treat" & missing == 0, y]) - mean(d[treat == "control" & missing == 0, y])
mod <- glm(!missing ~ (gender + edu + bum), # note this klugey solution to fixing the point that
data   = d,                      # max brought up. max noted that i was using weighted
family = "binomial" )
mod2 <- glm(!missing ~ treat, data = d, family = "binomial")
mod3 <- glm(!missing ~ treat * (gender + edu + bum),
data   = d,
family = "binomial" ) # default to "logit"
summary(mod)
mod$fitted
d[ , weights := 1 / mod$fitted ]
ateMod <- glm(y ~ treat + gender + edu + bum,
data    = d,
family  = "gaussian"
, weights = weights
)
summary(ateMod)
getwd()
rm( list = ls() )
setwd(dir = "/Users/GDC/MIDS/DATASCI_W241/Assignments/Problem Set 5/")
d <- read.csv("ps5_no2.csv")
View(d)
View(d)
View(d)
mod <- lm(income ~ years_education)
summary(mod)
mod <- lm(income ~ years_education, data = d)
summary(mod)
fibmat
mod <- lm(income ~ years_education, data = d)
summary(mod)
View(d)
View(d)
d <- d %>%
dplyr::mutate(hrd = ifelse(draft_number<=80, 1, 0)
)
mod <- lm(years_education ~ hrd, data = d)
summary(mod)
d <- d %>%
dplyr::mutate(hrd = ifelse(draft_number>80, 1, 0)
)
mod <- lm(years_education ~ hrd, data = d)
summary(mod)
d <- d %>%
dplyr::mutate(hrd = ifelse(draft_number<=80, 1, 0)
)
mod <- lm(years_education ~ hrd, data = d)
summary(mod)
d %>%
dplyr::group_by(hrd) %>%
dplyr::summarise(mean(income))
d %>%
dplyr::group_by(hrd) %>%
dplyr::summarise(mean(years_education))
cl <- function(fm, cluster){
require(sandwich, quietly = TRUE)
require(lmtest, quietly = TRUE)
M <- length(unique(cluster))
N <- length(cluster)
K <- fm$rank
dfc <- (M/(M-1))*((N-1)/(N-K))
uj <- apply(estfun(fm),2, function(x) tapply(x, cluster, sum));
vcovCL <- dfc*sandwich(fm, meat=crossprod(uj)/N)
coeftest(fm, vcovCL)
}
cl(lm(years_education ~ hrd,d), d$draft_number)
cl(lm(years_education ~ hrd,d), d$draft_number)
install.packages(c("sandwich","AER","foreign"))
install.packages(c("sandwich", "AER", "foreign"))
cl(lm(years_education ~ hrd,d), d$draft_number)
summary(lm(years_education ~ hrd, data = d))
mod <- cl(lm(years_education ~ hrd,d), d$draft_number)
mod
mod$coefficients[2,1]
mod[1]
mod[2,1]
cat(" ATE = ", mod$[2,1], "conf interval = ", c(mod$[2,1] - 1.96 * mod$[2,2], mod$[2,1] + 1.96*mod$[2,2]))
cat(" ATE = ", mod[2,1], "conf interval = ", c(mod[2,1] - 1.96 * mod[2,2], mod[2,1] + 1.96*mod[2,2]))
cat(" ATE = ", mod[2,1], "conf interval = ", c(mod[2,1] - 1.96 * mod[2,2], "-", mod[2,1] + 1.96*mod[2,2]))
mod <- cl(lm(income ~ hrd,d), d$draft_number)
cat(" ATE = ", mod[2,1], "conf interval = ", c(mod[2,1] - 1.96 * mod[2,2], "-", mod[2,1] + 1.96*mod[2,2]))
mod <- cl(lm(income ~ hrd,d), d$draft_number)
cat(" ATE = ", mod[2,1],"std. error =", mod[2,2], "conf interval = ", c(mod[2,1] - 1.96 * mod[2,2], "-", mod[2,1] + 1.96*mod[2,2]))
cat(" ATE = ", mod[2,1]," std. error =", mod[2,2],  "conf interval = ", c(mod[2,1] - 1.96 * mod[2,2], "-", mod[2,1] + 1.96*mod[2,2]))
##create dummy
d <- d %>%
dplyr::mutate(hrd = ifelse(draft_number<=80, 1, 0)
)
#mod <- summary(lm(years_education ~ hrd, data = d))
#summary(mod)
mod.edu <- cl(lm(years_education ~ hrd,d), d$draft_number)
cat(" ATE = ", mod.edu[2,1], "conf interval = ", c(mod.edu[2,1] - 1.96 * mod.edu[2,2], "-", mod.edu[2,1] + 1.96*mod.edu[2,2]))
mod.inc <- cl(lm(income ~ hrd,d), d$draft_number)
cat(" ATE = ", mod.inc[2,1]," std. error =", mod.inc[2,2],  "conf interval = ", c(mod.inc[2,1] - 1.96 * mod.inc[2,2], "-", mod.inc[2,1] + 1.96*mod.inc[2,2]))
mod.inc[2,1]/mod.edu[2,1]
mod.inc
d[ , length(income), by = draftnum]
d[ , length(income), by = draft_number]
d[ , length(income), by = draft_number]
[ , length(income), by = draft_number]
d[ , length(income), by = draft_number]
d %>%
dplyr::group_by(draft_number) %>%
dplyr::summarise(sum(income))
d %>%
dplyr::group_by(draft_number) %>%
dplyr::summarize(sum(income))
d %>%
dplyr::group_by(draft_number) %>%
dplyr::summarize(mean(income))
d %>%
dplyr::group_by(draft_number) %>%
dplyr::summarize(mean(income))
library(dplyr)
library(dplyr)
library(stargazer)
library(memisc)
library(data.table)
d %>%
dplyr::group_by(draft_number)
d %>%
dplyr::group_by(draft_number) %>%
dplyr::summarize(sum(income))
d %>%
dplyr::group_by(draft_number) %>%
dplyr::summarize(length(income))
d_test <- d %>%
dplyr::group_by(draft_number) %>%
dplyr::summarize(length(income))
View(d_test)
d_test <- d %>%
dplyr::group_by(draft_number) %>%
dplyr::summarize(cnt = length(income))
cl(lm(cnt ~ I(ifelse(draft_number<=80, 1, 0)), d_test), d_test$draft_number)
