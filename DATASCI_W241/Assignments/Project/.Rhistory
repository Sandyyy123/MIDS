d[ , group := c(rep("baseline", 2572),
rep("treatment", sum(486, 2086)),
rep("placebo", sum(470, 2109)))
]
d[ , treated  := c(rep(0, 2572), rep(1, 486), rep(0, 2086), rep(1, 470), rep(0, 2109)) ]
## fill yes/no function
yesNo <- function(N, pct) {
k <- round(N * pct, 0)
k1 <- N - k
c(rep(1, k), rep(0, k1))
View(d)
View(d)
colnames(df) <- c("pvalue","pass")
;
;;;;
fafa
;
21341+222
;
();
rm(list<-ls())
rm(listls())
rm( list = ls() )
d <- data.frame(running = runif(1000, min = 0, max = 10),
cov1    = rnorm(1000))
install.packages(c("ggplot2"))
View(d)
d$y <- d$running * .5 - .2 * d$cov1 + 1 * I(d$running > 5) + rnorm(1000)
d$y <- d$running * .5 - .2 * d$cov1 + 1 * I(d$running > 5) + rnorm(1000)
View(d)
hist(d$y)
plot(x = d$running, y = d$y, pch = 19, col = rgb(0,1,0, .4), ylim = c(-2, 10))
lines(lowess(x = , y = ))
lines(lowess(x = , y = ))
lines(lowess(x = d$running , y = d$y ))
install.packages(c("stargazer"))
install.packages(c("bestGLM"))
install.packages(c("bestglm"))
?lowess
library(dplyr)
cuttoff <- 5
plot(x = , y = , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
View(d)
View(d)
View(d)
d_lower <- d %>%
filter(running < cutoff)
View(d)
d$cutoff <- 5
d_lower <- d %>%
filter(running < cutoff)
d_higher <- d %>%
filter(running > cutoff)
plot(x = d$running , y = d$y , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
plot(x = d$running , y = d$y , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
lines(lowess(x = d_lower$running , y = d_lower$y ), lwd = 2) # lower than cuttoff
lines(lowess(x = d_higher$running, y = d_higher$y), lwd = 2) # higher than cuttoff
d$cutoff <- 3
d_lower <- d %>%
filter(running < cutoff)
d_higher <- d %>%
filter(running > cutoff)
plot(x = d$running , y = d$y , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
lines(lowess(x = d_lower$running, y = d_lower$y ), lwd = 2) # lower than cuttoff
lines(lowess(x = d_higher$running, y = d_higher$y), lwd = 2) # higher than cuttoff
for(i in 1:9) {
d$cutoff <- i
d_lower <- d %>%
filter(running < cutoff)
d_higher <- d %>%
filter(running > cutoff)
plot(x = d$running , y = d$y , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
lines(lowess(x = d_lower$running, y = d_lower$y ), lwd = 2) # lower than cuttoff
lines(lowess(x = d_higher$running, y = d_higher$y), lwd = 2) # higher than cuttoff
}
for(i in 1:9) {
d$cutoff <- i
d_lower <- d %>%
filter(running < cutoff)
d_higher <- d %>%
filter(running > cutoff)
plot(x = d$running , y = d$y , pch = 19, col = rgb(0,0,1, .4), ylim = c(-2, 10))
lines(lowess(x = d_lower$running, y = d_lower$y ), lwd = 2) # lower than cuttoff
lines(lowess(x = d_higher$running, y = d_higher$y), lwd = 2) # higher than cuttoff
}
install.packages("rdrobust")
library(rdrobust)
data(rdrobust_RDsenate)
d2 <- rdrobust_RDsenate
with(d2, rdplot(y = vote, x = margin,
title = "RD Plot - Senate Elections Data",
y.label = "Vote Share in Election at time t+1",
x.label = "Vote Share in Election at time t") )
R.version()
R.version
##############################
## Setup
##############################
## Clear environment variables
rm( list = ls())
## Set Working Directory
setwd("MIDS/DATASCI_W241/Assignments/Project/")
## Load relevant libraries
library(pryr)
library(memisc)
library(stringr)
library(stargazer)
library(dplyr)
library(ggplot2)
library(data.table)
library(lubridate)
library(RDSTK)
## Define Relevant Functions
coalesce2 <- function(...) {
Reduce(function(x, y) {
i <- which(is.na(x))
x[i] <- y[i]
x},
list(...))
}
##############################
## Data Processing
##############################
## Read in Data
pd.raw <- read.csv("Full Data Collection - Cleaned.csv", header=TRUE, stringsAsFactors=FALSE
, fileEncoding="latin1", na.strings=c("","NA"))
#remove dups
by_ips <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
select(V6) %>%
mutate(ip=V6) %>%
group_by(V6) %>%
summarise(bpcnt = count(ip))
duplicate_ips <- data.frame(by_ips$bpcnt$x, by_ips$bpcnt$freq)
names(duplicate_ips) <- c("x","freq")
duplicate_ips <- duplicate_ips %>%
filter(freq>1)
#recreate with dups removed
pd.raw <- pd.raw %>%
filter(!(V6 %in% duplicate_ips$x))
## General Information DF
pd.gen <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
##leverage lubridate mdy_hm to convert to dates
mutate(  gen_StartDate = mdy_hm(V8)
, gen_EndDate = mdy_hm(V9)
, gen_TotalTimeSpentMinutes = gen_EndDate - gen_StartDate
##leverage cases function from memiscv for label assignment
, gen_Gender = cases("Male"=Q7==1,
"Female"=Q7==2,
"Prefer not to respond"=Q7==3)
, gen_Age = as.numeric(Q5)+14
, gen_Education = cases("Less than High School"=Q2==1,
"High School / GED"=Q2==2,
"Some College"=Q2==3,
"2-year College Degree"=Q2==4,
"4-year College Degree"=Q2==5,
"Masters Degree"=Q2==6,
"Doctoral Degree"=Q2==7,
"Professional Degree (JD, MD)"=Q2==8)
, gen_Role = cases("Owner / Founder"=Q53==1,
"Executive Officer"=Q53==2,
"Director"=Q53==3,
"Manager"=Q53==4,
"Employee"=Q53==5,
"None of these apply"=Q53==6
)
, gen_Industry = cases("Construction"=Q10==1,
"Education"=Q10==2,
"Financial Activities"=Q10==3,
"Health Care or Pharmecuticals"=Q10==4,
"Information"=Q10==5,
"Leisure and Hospitality"=Q10==6,
"Manufacturing"=Q10==7,
"Natural Resources and Mining"=Q10==8,
"Professional and Business Services"=Q10==9,
"Trade, Transportation and Utilites"=Q10==10,
"None of these apply"=Q10==11)
#, gen_State = as.vector(fromJSON(coordinates2politics(LocationLatitude, LocationLongitude))))$politics.name.1)
, gen_PageOneTimeMinutes = (as.numeric(Q56_2)-as.numeric(Q56_1))/60
#, gen_PageOneTimePercentOfTotal = as.numeric(gen_PageOneTimeMinutes)/as.numeric(gen_TotalTimeSpentMinutes)*100
, gen_PageOneNumberClicks = as.numeric(Q56_4)
) %>%
#Only keep observations that finished
filter(V10==1) %>%
##only retain IPAddress & "gen_" columns
select(IPAddress = V6, starts_with("gen_"))
## IQ Test Information DF
pd.iq <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(  iq_Question1Response = Q25
, iq_Question1CorrectAnswer = ifelse(Q25==1,1,0)
, iq_Question2Response = Q59
, iq_Question2CorrectAnswer = ifelse(Q59==4,1,0)
, iq_Question3Response = Q27
, iq_Question3CorrectAnswer = ifelse(Q27==2,1,0)
, iq_TotalCorrect = iq_Question1CorrectAnswer+iq_Question2CorrectAnswer+iq_Question3CorrectAnswer
, iq_PercentageCorrect = iq_TotalCorrect/3
, iq_PageTwoTimeMinutes = (as.numeric(Q57_2)-as.numeric(Q57_1))/60
, iq_PageTwoNumberClicks = as.numeric(Q57_4)) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("iq_"))
## Experiment 1 Information DF
pd.exp1 <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(  temp_Treat1 = ifelse(Q19==1,"Nonordered chart junk",NA)
,temp_Treat2 = ifelse(Q20==1,"Nonordered table",NA)
,temp_Treat3 = ifelse(Q21==1,"Nonordered tufte",NA)
,temp_Treat4 = ifelse(Q23==1,"Ordered chart junk",NA)
,temp_Treat5 = ifelse(Q24==1,"Ordered Table",NA)
,temp_Treat6 = ifelse(Q25.1==1,"Ordered tufte",NA)
##use coalesce function to get everything in a single column
,exp1_Treatment = coalesce2(temp_Treat1,temp_Treat2,temp_Treat3,temp_Treat4,temp_Treat5,temp_Treat6)
,exp1_Question1Response = Q27.1
,exp1_Question1CorrectAnswer = ifelse(Q27.1==3,1,0)
,exp1_Question2Response = Q29
,exp1_Question2CorrectAnswer = ifelse(Q29==3,1,0)
,exp1_Question3Response = Q28
,exp1_Question3CorrectAnswer = ifelse(Q28==3,1,0)
,exp1_Question4Response = Q29
,exp1_Question4CorrectAnswer = ifelse(Q29==1,1,0)
,exp1_TotalCorrect = exp1_Question1CorrectAnswer+exp1_Question2CorrectAnswer+exp1_Question3CorrectAnswer+exp1_Question4CorrectAnswer
,exp1_PercentageCorrect = exp1_TotalCorrect/4
,exp1_Question5Response = Q30
,exp1_PageThreeTimeMinutes = (as.numeric(Q20_2)-as.numeric(Q20_1))/60
,exp1_PageThreeNumberClicks = as.numeric(Q20_4)
##added this since pages were split up
,exp1_PageFourTimeMinutes = (as.numeric(Q71_2)-as.numeric(Q71_1))/60
,exp1_PageFourNumberClicks = as.numeric(Q71_4)
) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("exp1_"))
## Recall Information DF
## Could include Treatment but this can be joined on if necessary
pd.recall <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(    recall_Question1Response = Q31
,recall_Question1CorrectAnswer = ifelse(Q31==6,1,0)
,recall_Question2Response = Q32
,recall_Question2CorrectAnswer = ifelse(Q32==6,1,0)
,recall_Invalid = ifelse(!Q63==3,1,0)
,recall_TotalCorrect = recall_Question1CorrectAnswer+recall_Question2CorrectAnswer
,recall_PercentageCorrect = recall_TotalCorrect/2
,recall_PageFiveTimeMinutes = (as.numeric(Q34_2)-as.numeric(Q34_1))/60
,recall_PageFiveNumberClicks = as.numeric(Q34_4)) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("recall_"))
## Experiment 2 Information DF
pd.exp2 <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(  temp_Treat1 = ifelse(Q40==1,"Log scatterplot",NA)
,temp_Treat2 = ifelse(Q58==1,"No Log scatterplot",NA)
,temp_Treat3 = ifelse(Q42==1,"Unordered Table",NA)
,temp_Treat4 = ifelse(Q43==1,"Ordered Table",NA)
##use coalesce function to get everything in a single column
,exp2_Treatment = coalesce2(temp_Treat1,temp_Treat2,temp_Treat3,temp_Treat4)
,exp2_DisplayedTreatment = Q76
,exp2_Question1Response = Q35_1
,exp2_Question2Response = Q36
,exp2_Question2CorrectAnswer = ifelse(Q36==1,1,0)
##Should Question 1 have a correct answer??
,exp2_Question3Response = Q61
,exp2_Question3CorrectAnswer = ifelse(Q61==2,1,0)
,exp2_Question4Response = Q62
,exp2_Question4CorrectAnswer = ifelse(Q62==2,1,0)
,exp2_TotalCorrect = #exp2_Question1CorrectAnswer+
exp2_Question2CorrectAnswer+exp2_Question3CorrectAnswer+exp2_Question4CorrectAnswer
,exp2_PercentageCorrect = exp2_TotalCorrect/3
,exp2_PageSixTimeMinutes = (as.numeric(Q23_2)-as.numeric(Q23_1))/60
,exp2_PageSixNumberClicks = as.numeric(Q23_4)
,exp2_PageSevenTimeMinutes = (as.numeric(Q79_2)-as.numeric(Q79_1))/60
,exp2_PageSevenNumberClicks = as.numeric(Q79_4)
) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("exp2_"))
## Final Questions Information DF
pd.fq <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(finalq_Question1Response = Q38
,finalq_Question1CorrectAnswer = ifelse(Q38==5,1,0)
,finalq_Question2Response = Q37_1
,finalq_Question3Response = Q37_2
,finalq_PercentageCorrect = finalq_Question1CorrectAnswer
) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("finalq_"))
##############################
## Data Output
##############################
pd.cleaned <- inner_join(pd.gen, pd.iq, by = "IPAddress") %>%
inner_join(pd.exp1, by = "IPAddress") %>%
inner_join(pd.recall, by = "IPAddress") %>%
inner_join(pd.exp2, by = "IPAddress") %>%
inner_join(pd.fq, by = "IPAddress")
## Write Out Data For Easy Import
save(pd.cleaned, file="CourseProjectCleanedData.rda")
write.csv(pd.cleaned, file = "CourseProjectCleanedData.csv",row.names=FALSE, na="")
View(pd.exp2)
##############################
## Setup
##############################
## Clear environment variables
rm( list = ls())
## Set Working Directory
setwd("MIDS/DATASCI_W241/Assignments/Project/")
## Load relevant libraries
library(pryr)
library(memisc)
library(stringr)
library(stargazer)
library(dplyr)
library(ggplot2)
library(data.table)
library(lubridate)
library(RDSTK)
## Define Relevant Functions
coalesce2 <- function(...) {
Reduce(function(x, y) {
i <- which(is.na(x))
x[i] <- y[i]
x},
list(...))
}
##############################
## Data Processing
##############################
## Read in Data
pd.raw <- read.csv("Full Data Collection - Cleaned.csv", header=TRUE, stringsAsFactors=FALSE
, fileEncoding="latin1", na.strings=c("","NA"))
#remove dups
by_ips <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
select(V6) %>%
mutate(ip=V6) %>%
group_by(V6) %>%
summarise(bpcnt = count(ip))
duplicate_ips <- data.frame(by_ips$bpcnt$x, by_ips$bpcnt$freq)
names(duplicate_ips) <- c("x","freq")
duplicate_ips <- duplicate_ips %>%
filter(freq>1)
#recreate with dups removed
pd.raw <- pd.raw %>%
filter(!(V6 %in% duplicate_ips$x))
## General Information DF
pd.gen <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
##leverage lubridate mdy_hm to convert to dates
mutate(  gen_StartDate = mdy_hm(V8)
, gen_EndDate = mdy_hm(V9)
, gen_TotalTimeSpentMinutes = gen_EndDate - gen_StartDate
##leverage cases function from memiscv for label assignment
, gen_Gender = cases("Male"=Q7==1,
"Female"=Q7==2,
"Prefer not to respond"=Q7==3)
, gen_Age = as.numeric(Q5)+14
, gen_Education = cases("Less than High School"=Q2==1,
"High School / GED"=Q2==2,
"Some College"=Q2==3,
"2-year College Degree"=Q2==4,
"4-year College Degree"=Q2==5,
"Masters Degree"=Q2==6,
"Doctoral Degree"=Q2==7,
"Professional Degree (JD, MD)"=Q2==8)
, gen_Role = cases("Owner / Founder"=Q53==1,
"Executive Officer"=Q53==2,
"Director"=Q53==3,
"Manager"=Q53==4,
"Employee"=Q53==5,
"None of these apply"=Q53==6
)
, gen_Industry = cases("Construction"=Q10==1,
"Education"=Q10==2,
"Financial Activities"=Q10==3,
"Health Care or Pharmecuticals"=Q10==4,
"Information"=Q10==5,
"Leisure and Hospitality"=Q10==6,
"Manufacturing"=Q10==7,
"Natural Resources and Mining"=Q10==8,
"Professional and Business Services"=Q10==9,
"Trade, Transportation and Utilites"=Q10==10,
"None of these apply"=Q10==11)
#, gen_State = as.vector(fromJSON(coordinates2politics(LocationLatitude, LocationLongitude))))$politics.name.1)
, gen_PageOneTimeMinutes = (as.numeric(Q56_2)-as.numeric(Q56_1))/60
#, gen_PageOneTimePercentOfTotal = as.numeric(gen_PageOneTimeMinutes)/as.numeric(gen_TotalTimeSpentMinutes)*100
, gen_PageOneNumberClicks = as.numeric(Q56_4)
) %>%
#Only keep observations that finished
filter(V10==1) %>%
##only retain IPAddress & "gen_" columns
select(IPAddress = V6, starts_with("gen_"))
## IQ Test Information DF
pd.iq <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(  iq_Question1Response = Q25
, iq_Question1CorrectAnswer = ifelse(Q25==1,1,0)
, iq_Question2Response = Q59
, iq_Question2CorrectAnswer = ifelse(Q59==4,1,0)
, iq_Question3Response = Q27
, iq_Question3CorrectAnswer = ifelse(Q27==2,1,0)
, iq_TotalCorrect = iq_Question1CorrectAnswer+iq_Question2CorrectAnswer+iq_Question3CorrectAnswer
, iq_PercentageCorrect = iq_TotalCorrect/3
, iq_PageTwoTimeMinutes = (as.numeric(Q57_2)-as.numeric(Q57_1))/60
, iq_PageTwoNumberClicks = as.numeric(Q57_4)) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("iq_"))
## Experiment 1 Information DF
pd.exp1 <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(  temp_Treat1 = ifelse(Q19==1,"Nonordered chart junk",NA)
,temp_Treat2 = ifelse(Q20==1,"Nonordered table",NA)
,temp_Treat3 = ifelse(Q21==1,"Nonordered tufte",NA)
,temp_Treat4 = ifelse(Q23==1,"Ordered chart junk",NA)
,temp_Treat5 = ifelse(Q24==1,"Ordered Table",NA)
,temp_Treat6 = ifelse(Q25.1==1,"Ordered tufte",NA)
##use coalesce function to get everything in a single column
,exp1_Treatment = coalesce2(temp_Treat1,temp_Treat2,temp_Treat3,temp_Treat4,temp_Treat5,temp_Treat6)
,exp1_Question1Response = Q27.1
,exp1_Question1CorrectAnswer = ifelse(Q27.1==3,1,0)
,exp1_Question2Response = Q29
,exp1_Question2CorrectAnswer = ifelse(Q29==3,1,0)
,exp1_Question3Response = Q28
,exp1_Question3CorrectAnswer = ifelse(Q28==3,1,0)
,exp1_Question4Response = Q29
,exp1_Question4CorrectAnswer = ifelse(Q29==1,1,0)
,exp1_TotalCorrect = exp1_Question1CorrectAnswer+exp1_Question2CorrectAnswer+exp1_Question3CorrectAnswer+exp1_Question4CorrectAnswer
,exp1_PercentageCorrect = exp1_TotalCorrect/4
,exp1_Question5Response = Q30
,exp1_PageThreeTimeMinutes = (as.numeric(Q20_2)-as.numeric(Q20_1))/60
,exp1_PageThreeNumberClicks = as.numeric(Q20_4)
##added this since pages were split up
,exp1_PageFourTimeMinutes = (as.numeric(Q71_2)-as.numeric(Q71_1))/60
,exp1_PageFourNumberClicks = as.numeric(Q71_4)
) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("exp1_"))
## Recall Information DF
## Could include Treatment but this can be joined on if necessary
pd.recall <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(    recall_Question1Response = Q31
,recall_Question1CorrectAnswer = ifelse(Q31==6,1,0)
,recall_Question2Response = Q32
,recall_Question2CorrectAnswer = ifelse(Q32==6,1,0)
,recall_Invalid = ifelse(!Q63==3,1,0)
,recall_TotalCorrect = recall_Question1CorrectAnswer+recall_Question2CorrectAnswer
,recall_PercentageCorrect = recall_TotalCorrect/2
,recall_PageFiveTimeMinutes = (as.numeric(Q34_2)-as.numeric(Q34_1))/60
,recall_PageFiveNumberClicks = as.numeric(Q34_4)) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("recall_"))
## Experiment 2 Information DF
pd.exp2 <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(  temp_Treat1 = ifelse(Q40==1,"Log scatterplot",NA)
,temp_Treat2 = ifelse(Q58==1,"No Log scatterplot",NA)
,temp_Treat3 = ifelse(Q42==1,"Unordered Table",NA)
,temp_Treat4 = ifelse(Q43==1,"Ordered Table",NA)
##use coalesce function to get everything in a single column
,exp2_Treatment = coalesce2(temp_Treat1,temp_Treat2,temp_Treat3,temp_Treat4)
,exp2_DisplayedTreatment = Q76
,exp2_Question1Response = Q35_1
,exp2_Question2Response = Q36
,exp2_Question2CorrectAnswer = ifelse(Q36==1,1,0)
##Should Question 1 have a correct answer??
,exp2_Question3Response = Q61
,exp2_Question3CorrectAnswer = ifelse(Q61==2,1,0)
,exp2_Question4Response = Q62
,exp2_Question4CorrectAnswer = ifelse(Q62==2,1,0)
,exp2_TotalCorrect = #exp2_Question1CorrectAnswer+
exp2_Question2CorrectAnswer+exp2_Question3CorrectAnswer+exp2_Question4CorrectAnswer
,exp2_PercentageCorrect = exp2_TotalCorrect/3
,exp2_PageSixTimeMinutes = (as.numeric(Q23_2)-as.numeric(Q23_1))/60
,exp2_PageSixNumberClicks = as.numeric(Q23_4)
,exp2_PageSevenTimeMinutes = (as.numeric(Q79_2)-as.numeric(Q79_1))/60
,exp2_PageSevenNumberClicks = as.numeric(Q79_4)
) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("exp2_"))
## Final Questions Information DF
pd.fq <- pd.raw %>%
slice(2:nrow(pd.raw)) %>%
mutate(finalq_Question1Response = Q38
,finalq_Question1CorrectAnswer = ifelse(Q38==5,1,0)
,finalq_Question2Response = Q37_1
,finalq_Question3Response = Q37_2
,finalq_PercentageCorrect = finalq_Question1CorrectAnswer
) %>%
filter(V10==1) %>%
##only retain IPAddress & "iq_" columns
select(IPAddress = V6, starts_with("finalq_"))
##############################
## Data Output
##############################
pd.cleaned <- inner_join(pd.gen, pd.iq, by = "IPAddress") %>%
inner_join(pd.exp1, by = "IPAddress") %>%
inner_join(pd.recall, by = "IPAddress") %>%
inner_join(pd.exp2, by = "IPAddress") %>%
inner_join(pd.fq, by = "IPAddress")
##Update Factors for exp1_Treatment
pd.cleaned$exp1_Treatment <- factor(pd.cleaned$exp1_Treatment,levels(pd.cleaned$exp1_Treatment)[c(2,1,3,4,5,6)])
## Write Out Data For Easy Import
save(pd.cleaned, file="CourseProjectCleanedData.rda")
write.csv(pd.cleaned, file = "CourseProjectCleanedData.csv",row.names=FALSE, na="")
