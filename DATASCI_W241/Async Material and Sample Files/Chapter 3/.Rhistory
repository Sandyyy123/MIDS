if (i %% round(numiter/10) == 0) cat("Iteration",i,"of",numiter,"\n")
}
a.pvalue <- round(sum(a.tauRI >= a.ate)/numiter,3)
a.pvalue
sum(a.tauRI >= a.ate
sum(a.tauRI >= a.ate)
sum(a.tauRI >= a.ate)
a.ate
a.tauRI
data <- read.csv("GerberGreenBook_Chapter3_Table_3_3.csv",header = TRUE)
View(data)
c<-data
c
kansas <- read.dta("Arceneaux_AAAPSSsubset_2005.dta")
clust <- kansas$unit
Z <-  kansas$treatmen
Y <- kansas$vote03
clust <- kansas$unit
View(c)
.005*100
cws <-  1
advertising <- .10
users <- 1:1000000
profit <- 100
conversion <- .005
length(users)
length(users)*conversion
averagesales<- length(users)*conversion*profit
averagesales
length(users)*conversion*profit
options("scipen"=100, "digits"=4)
averagesales<- length(users)*conversion*profit
averagesales
length(users)*.10
length(users)*conversion*profit
length(users)*.006*profit
length(users)*.0061*profit
length(users)*.0060001*profit
length(users)*.00600001*profit
600000/(length(users)*profit)
cost<-length(users)*.10
requiredconversion <- (averagesales+cost+1)/(length(users)*profit)
requiredconversion
#problem set up
options("scipen"=100, "digits"=10)
averagesales<- length(users)*conversion*profit
averagesales
cost<-length(users)*.10
requiredconversion <- (averagesales+cost+1)/(length(users)*profit)
requiredconversion
required.increase <- (required.conversion - conversion)/conversioin*100
required.increase
options("scipen"=100, "digits"=10)
average.sales<- length(users)*conversion*profit
average.sales
cost<-length(users)*.10
required.conversion <- (average.sales+cost+1)/(length(users)*profit)
required.increase <- (required.conversion - conversion)/conversion*100
required.increase
measuredeffect<-.002
(length(users)/2)*measuredeffect
(length(users)/2)*measuredeffect+conversion
(length(users)/2)*(measuredeffect+conversion)
treatment <- (length(users)/2)*(measuredeffect+conversion)
control <- (length(users)/2)*(conversion)
(length(users)/2)*(conversion)
prop.test(x=c(treatment,control),n=((length(users)/2),(length(users)/2)))
size<-length(users)/2
prop.test(x=c(treatment,control),n=c(size,size))
(treatment+control)/(size+size)
se <- (treatment+control)/(size+size)(1-(treatment+control)/(size+size))/((1/size)+(1/size))
((treatment+control)/(size+size)(1-(treatment+control)/(size+size)))
(1-(treatment+control))
p<-(treatment+control)/(size+size)
p
p(1-p)/((1/size)+(1/size))
p*(1-p)
p*(1-p)/((1/size)+(1/size))
se <- sqrt(p*(1-p)/((1/size)+(1/size)))
se
prop.test(x=c(treatment,control),n=c(size,size))
treatment+se*1.96
conf<- c(treatment-se*1.96, treatment+se*1.96)
conf
size.control<-length(users)*(.01)
size.control
size.treatment<-length(users)*(.99)
size.control<-length(users)*(.01)
(size.treatment)*(measuredeffect+conversion)
(size.control)*(conversion)
p<-(treatment+control)/(size.treatment+size.control)
p
se <- sqrt(p*(1-p)/((1/size)+(1/size)))
se
measuredeffect<-.002
size.treatment<-length(users)*(.99)
size.control<-length(users)*(.01)
treatment <- (size.treatment)*(measuredeffect+conversion)
control <- (size.control)*(conversion)
#prop.test(x=c(treatment,control),n=c(size.treatment,size.control))
p<-(treatment+control)/(size.treatment+size.control)
p
se <- sqrt(p*(1-p)/((1/size)+(1/size)))
se
conf<- c(treatment-se*1.96, treatment+se*1.96)
conf
data <- read.csv("PS 2 data - list_luckingreiley_auction_data.csv",header = TRUE)
View(data)
r<-data
View(r)
by(r$bid, r$uniform_price_auction, mean, na.rm = TRUE)
qqnorm(r$bid)
shapiro.test(r$bid)
t.test(r$bid ~ r$uniform_price_auction, r)
t.test(r$bid ~ r$uniform_price_auction, r, alternative = "two.sided")
qqnorm(r$bid ~ r$uniform_price_auction)
library("cars")
library("cars")
library(car)
scatterplot(r$bid ~ r$uniform_price_auction)
scatterplot(r$bid, r$uniform_price_auction)
scatterplot( $uniform_price_auction,r$bid,)
scatterplot( $uniform_price_auction,r$bid,)
scatterplot( $uniform_price_auction,r$bid)
scatterplot(r$uniform_price_auction,r$bid)
scatterplot(r$uniform_price_auction,r$bid)
scatterplot(r$bid,r$uniform_price_auction)
lm(uniform_price_auction ~ bid, data = r)
model = lm(uniform_price_auction ~ bid, data = r)
summary(model)
model = lm(bid~uniform_price_auction, data = r)
summary(model)
t.test(r$bid ~ r$uniform_price_auction, r, alternative = "two.sided")
model$coefficients[2,2]
model$coefficients
model$coefficients[2,1]
model$coefficients[1,1]
model$coefficients
model$coefficients[1]
model$coefficients[2]
model$coefficients[1,1]
estimate <- model$coefficients[1]
estimate
unlist(model$coefficients[1])
as.vector(model$coefficients[1])
estimate <- as.vector(model$coefficients[1])
standard.error <- abs(as.vector(model$coefficients[2]))
lower.bound <- estimate - standard.error * 1.96
upper.bound <- estimate + standard.error * 1.96
summary(model)
cat("Conf Interval = ", lower.bound, upper.bound)
names(model)
names(summary(model))
anova(model)
names(anova(model))
anova<- anova(model)
cat("p-value = ", anova$Pr(>F))
cat("p-value = ", anova$Pr(>F))
anova$Pr(>F)
anova[5]
cat("p-value = ", summary(model)$coefficients[,4])
summary(model)
easuredeffect<-.002
size.treatment<-length(users)*(.99)
size.control<-length(users)*(.01)
treatment <- (size.treatment)*(measuredeffect+conversion)
control <- (size.control)*(conversion)
#prop.test(x=c(treatment,control),n=c(size.treatment,size.control))
p<-(treatment+control)/(size.treatment+size.control)
sqrt(p*(1-p)*((1/size)+(1/size)))
sqrt(p*(1-p)/((1/size)+(1/size)))
(1/size)+(1/size)
(p*(1-p))
(p*(1-p))*((1/size)+(1/size))
cws <-  1
advertising <- .10
users <- 1:1000000
profit <- 100
conversion <- .005
options("scipen"=100, "digits"=10)
average.sales<- length(users)*conversion*profit
average.sales
cost<-length(users)*.10
required.conversion <- (average.sales+cost+1)/(length(users)*profit)
required.increase <- (required.conversion - conversion)/conversion*100
required.increase
measuredeffect<-.002
size<-length(users)/2
treatment <- (length(users)/2)*(measuredeffect+conversion)
control <- (length(users)/2)*(conversion)
(treatment+control)/(size+size)
p*(1-p)
((1/size)+(1/size)
(1/size)+(1/size)
((1/size)+(1/size)
((1/size)+(1/size))
1/size
size<-length(users)/2
(1/size)+(1/size)
sqrt(p*(1-p)/((1/size)+(1/size)))
sqrt(p*(1-p)*((1/size)+(1/size)))*size
sqrt((p*(1-p))*((1/size)+(1/size)))*size
(p*(1-p)
(p*(1-p))
p*(1-p)
(treatment+control)/(size+size)
size+size
control
treatment
p<-(treatment+control)/(size+size)
p
p*(1-p)
(1/size)+(1/size)
2/500000
0.005964*0.000004
sqrt(0.000000023856)
sqrt(0.000000023856)*size
p*(1-p)*((1/size)+(1/size))
sqrt(p*(1-p)*((1/size)+(1/size)))
se <- sqrt(p*(1-p)*((1/size)+(1/size)))*size
se
conf<- c(treatment-se*1.96, treatment+se*1.96)
conf
sqrt(p*(1-p)*((1/size.treatment)+(1/size.control)))
sqrt(p*(1-p)*((1/size.treatment)+(1/size.control)))*size.treatment
se <- sqrt(p*(1-p)*((1/size.treatment)+(1/size.control)))*size.treatment
se
measuredeffect<-.002
size.treatment<-length(users)*(.99)
size.control<-length(users)*(.01)
treatment <- (size.treatment)*(measuredeffect+conversion)
control <- (size.control)*(conversion)
#prop.test(x=c(treatment,control),n=c(size.treatment,size.control))
p<-(treatment+control)/(size.treatment+size.control)
p
se <- sqrt(p*(1-p)*((1/size.treatment)+(1/size.control)))*size.treatment
se
conf<- c(treatment-se*1.96, treatment+se*1.96)
conf
Y_0<-c(0,1,2,4,4,6,6,9,14,15,16,16,17,18)
Y_1<-c(0,0,1,2,0,0,2,3,12,9,8,15,5,17)
Y_j_0<-c(0,0,0,0,0,0,0)
Y_j_1<-c(0,0,0,0,0,0,0)
for (i in 1:7 ) {
Y_j_0[i]<-(Y_0[2*i-1] + Y_0[2*i])/2
Y_j_1[i]<-(Y_1[2*i-1] + Y_1[2*i])/2
}
View(r)
Y <- r$bid
Z <- r$uniform_price_auction
denom <- var(Z)
tau <- cov(Y,Z)/denom
tauRI <- rep(NA,numiter)
for (i in 1:numiter) {
Zri <- sample(Z)
tauRI[i] <- cov(Y,Zri)/denom
if (i %% round(numiter/10) == 0) cat("Iteration",i,"of",numiter,"\n")
}
pvalue <- round(sum(tauRI >= tau)/numiter,3)
pvalue
numiter <- 10000 # number of RI iterations. Use more for greater precision, fewer for greater speed.
set.seed(12) # set random number seed (so that results can be replicated)
# Compute RI Distribution
Y <- r$bid
Z <- r$uniform_price_auction
denom <- var(Z)
tau <- cov(Y,Z)/denom
tauRI <- rep(NA,numiter)
for (i in 1:numiter) {
Zri <- sample(Z)
tauRI[i] <- cov(Y,Zri)/denom
if (i %% round(numiter/10) == 0) cat("Iteration",i,"of",numiter,"\n")
}
pvalue <- round(sum(tauRI >= tau)/numiter,3)
pvalue
dataf <- read.csv("GerberGreenBook_Chapter3_Donations.csv",head=TRUE,sep=",") # enter your file name here
# Advanced Options
numiter <- 10000 # number of RI iterations. Use more for greater precision, fewer for greater speed.
set.seed(1234567) # set random number seed (so that results can be replicated)
# Compute RI Distribution
Y <- dataf$Y
Z <- dataf$Z
denom <- var(Z)
tau <- cov(Y,Z)/denom
tauRI <- rep(NA,numiter)
for (i in 1:numiter) {
Zri <- sample(Z)
tauRI[i] <- cov(Y,Zri)/denom
if (i %% round(numiter/10) == 0) cat("Iteration",i,"of",numiter,"\n")
}
# RI distribution output
hist(tauRI,freq=TRUE,xlab="Estimated ATE",main=paste("Distribution of the Estimated ATE\n under the Sharp Null Hypothesis of No Treatment Effect\np = ",round(sum(tauRI >= tau)/numiter,3),", SE = ",round(sd(tauRI),3),sep=""),breaks=numiter,lwd=1)
lines(x=c(tau,tau),y=c(-1000,numiter*2),lwd=2,col="red",lty=2)
pvalue <- round(sum(tauRI >= tau)/numiter,3)
pvalue
denom <- var(Z)
Z <- r$uniform_price_auction
Z
var(X)
var(Z)
Z <- r$uniform_price_auction
denom <- var(Z)
tau <- cov(Y,Z)/denom
tau <- cov(Y,Z)/denom
tau <- cov(Y,Z)/denom
Y <- r$bid
Y <- r$bid
Y <- r$bid
denom <- var(Z)
tau <- cov(Y,Z)/denom
tauRI <- rep(NA,numiter)
for (i in 1:numiter) {
Zri <- sample(Z)
tauRI[i] <- cov(Y,Zri)/denom
if (i %% round(numiter/10) == 0) cat("Iteration",i,"of",numiter,"\n")
}
pvalue <- round(sum(tauRI >= tau)/numiter,3)
pvalue
pvalue
t.test(Y~Z,var.equal=FALSE,alternative= "less")
t.test(Y~Z,var.equal=TRUE,alternative= "less")
t.test(Y~Z,var.equal=FALSE,alternative = "two.sided")
pvalue <- round(sum(abs(tauRI) >= tau)/numiter,3)
pvalue
pvalue <- round(sum(tauRI >= abs(tau))/numiter,3)
pvalue
# compare with traditional t-tests
t.test(Y~Z,var.equal=FALSE,alternative = "two.sided")
measuredeffect<-.002
size.treatment<-length(users)*(.99)
size.control<-length(users)*(.01)
treatment <- (size.treatment)*(measuredeffect+conversion)
control <- (size.control)*(conversion)
#prop.test(x=c(treatment,control),n=c(size.treatment,size.control))
p<-(treatment+control)/(size.treatment+size.control)
p
se <- sqrt(p*(1-p)*((1/size.treatment)+(1/size.control)))*size.treatment
se
#confidence interval
conf<- c(treatment-se*1.96, treatment+se*1.96)
conf
setwd("MIDS/DATASCI_W241/Async Material and Sample Files/Chapter 3/")
getwd()
getwd()
data <- read.csv("Clingingsmith_et_al_QJE_2009dta.csv", sep=",", header = TRUE)
rm( list = ls() )
data <- read.dta("Titiunik_WorkingPaper_2010.csv.dta")
setwd("MIDS/DATASCI_W241/Async Material and Sample Files/Chapter 3/")
setwd("MIDS/DATASCI_W241/Async Material and Sample Files/Chapter 2/")
pwd
getwd()
setwd("/Users/ceccarelli/MIDS/DATASCI_W241/Async Material and Sample Files/Chapter 3)
data <- read.dta("Titiunik_WorkingPaper_2010.csv.dta")
data <- read.dta("Titiunik_WorkingPaper_2010.csv.dta")
library("foreign")
#read in tabular data
data <- read.dta("Titiunik_WorkingPaper_2010.csv.dta")
#create shorthand reference
t<-data
require("foreign")
#read in tabular data
data <- read.dta("Titiunik_WorkingPaper_2010.csv.dta")
#create shorthand reference
t<-data
View(t)
setwd("/Users/ceccarelli/MIDS/DATASCI_W241/Async Material and Sample Files/Chapter 3")
#clear variables
rm( list = ls() )
require("foreign")
#read in tabular data
data <- read.dta("Titiunik_WorkingPaper_2010.csv.dta")
#create shorthand reference
t<-data
setwd("/Users/ceccarelli/MIDS/DATASCI_W241/Async Material and Sample Files/Chapter 3")
#clear variables
rm( list = ls() )
#read in tabular data
data <- read.csv("GerberGreenBook_Chapter3_Table_3_3.csv",header = TRUE)
#create shorthand reference
c<-data
View(c)
library(foreign)    # package allows R to read Stata datasets
kansas <- read.dta("Arceneaux_AAAPSSsubset_2005.dta")
clust <- kansas$unit
View(kansas)
Z <-  kansas$treatmen
Y <- kansas$vote03
clust <- kansas$unit
covs <- as.matrix(kansas[,2:21])  # covariates are past voter turnout if you care to perform a randomization check
probs <- genprobexact(Z,clustvar=clust)  # subjects are clustered by precinct
numiter <- 1000  # actual number of randomizations in this case is 40116600
perms <- genperms(Z,maxiter=numiter,clustvar=clust)    # clustered assignment
numiter <- ncol(perms)
group
n.classrooms <- 8
n.students <- 16
classroom.ids <- unlist(lapply(1:n.classrooms, function(x)
rep(x,times=n.students)))
classroom.ids
c
n.classrooms <- 8
n.students <- 16
classroom.ids <- unlist(lapply(1:n.classrooms, function(x)
rep(x,times=n.students)))
classroom.ids
all.classrooms <- unique(classroom.ids)
all.classrooms
classroom.level.noise <- rnorm(length(all.classrooms))
classroom.level.noise
student.outcomes.control <- rnorm(length(classroom.ids)) +
classroom.level.noise[classroom.ids]
student.outcomes.control
student.outcomes.treat <- student.outcomes.control + 0.75
randomize.clustered <- function(){
treat.classroom.ids <- sample(all.classrooms, n.classrooms/2)
return(
as.numeric(classroom.ids %in% treat.classroom.ids)
)
}
randomize.clustered()
randomize.clustered <- function(){
treat.classroom.ids <- sample(all.classrooms, n.classrooms/3)
return(
as.numeric(classroom.ids %in% treat.classroom.ids)
)
}
randomize.clustered()
c
clusters<-c(1,1,2,2,3,3,4,4,5,5,7,7)
c$Y
c$D
clusters
cluster.ids<-c(1,1,2,2,3,3,4,4,5,5,7,7)
clusters.ids
all.clusters <- unique(clusters.ids)
cluster.ids<-c(1,1,2,2,3,3,4,4,5,5,7,7)
cluster.ids
all.clusters <- unique(cluster.ids)
all.clusters
all.clusters
length(all.clusters)
all.clusters
cluster.ids<-c(1,1,2,2,3,3,4,4,5,5,6,6,7,7)
cluster.ids
all.clusters <- unique(cluster.ids)
length(all.clusters)*(3/7)
randomize.clustered <- function(){
treat.cluster.ids <- sample(all.clusters, length(all.clusters)*(3/7))
return(
as.numeric(cluster.ids %in% treat.cluster.ids)
)
}
randomize.clustered()
randomize.clustered()
cbind(c$Y,c$D,randomize.clustered())
as.data.frame(cbind(c$Y,c$D,randomize.clustered()))
cl1<-as.data.frame(cbind(c$Y,c$D,randomize.clustered()))
names(c1)[1] <- "Y"
names(c1)[2] <- "D"
names(c1)[3] <- "Cluster"
cl1<-as.data.frame(cbind(c$Y,c$D,randomize.clustered()))
names(cl1)[1] <- "Y"
names(cl1)[2] <- "D"
names(cl1)[3] <- "Cluster"
cl1
subset(cl1,cl1$cluter)[1]
subset(cl1,cl1$cluster==0)[1]
subset(cl1,cl1$cluster==0)
subset(cl1,cl1$Cluster==0)
unlist(subset(cl1,cl1$Cluster==0)[1])
cl1.1 <- unlist(subset(cl1,cl1$Cluster==0)[2])
cl1.1
unlist(subset(cl1,cl1$Cluster==0)
subset(cl1,cl1$Cluster==0)
4*var(cl1.0)/(7-4)
cl1.0 <- unlist(subset(cl1,cl1$Cluster==0)[1])
cl1.1 <- unlist(subset(cl1,cl1$Cluster==0)[2])
var(cl1.0)
(4*var(cl1.0)/(7-4))
(3*var(cl1.1)/(4))
cov(cl1.0,cl1.1)
(1/(7-1))
(1/(7-1))*((4*var(cl1.0)/(7-4))+(3*var(cl1.1)/(4))+(2*cov(cl1.0,cl1.1)))
sqrt((1/(7-1))*((4*var(cl1.0)/(7-4))+(3*var(cl1.1)/(4))+(2*cov(cl1.0,cl1.1))))
setwd("/Users/ceccarelli/MIDS/DATASCI_W241/Async Material and Sample Files/Chapter 3")
#clear variables
rm( list = ls() )
#read in tabular data
data <- read.csv("GerberGreenBook_Chapter3_Table_3_3.csv",header = TRUE)
#create shorthand reference
c<-data
##View(c)
c$Y
c$D
cluster.ids<-c(1,2,3,4,5,6,7,7,6,5,4,3,2,1)
cluster.ids
all.clusters <- unique(cluster.ids)
randomize.clustered <- function(){
treat.cluster.ids <- sample(all.clusters, length(all.clusters)*(3/7))
return(
as.numeric(cluster.ids %in% treat.cluster.ids)
)
}
randomize.clustered()
cl1<-as.data.frame(cbind(c$Y,c$D,randomize.clustered()))
names(cl1)[1] <- "Y"
names(cl1)[2] <- "D"
names(cl1)[3] <- "Cluster"
cl1.0 <- unlist(subset(cl1,cl1$Cluster==0)[1])
cl1.1 <- unlist(subset(cl1,cl1$Cluster==0)[2])
se.ate <- sqrt((1/(7-1))*((4*var(cl1.0)/(7-4))+(3*var(cl1.1)/(4))+(2*cov(cl1.0,cl1.1))))
cat("SE for Cluster Assingment 2 = ", se.ate)
