install.packages("Rcmdr")
install.packages("ggplot2")
data.worldbank <-read.csv
?
2.45-2
/2
.45/2
pnorm(.225)
pnorm(2.45,2,2)
prime.sieve <- function(number, first_prime=2) {
##hold a vector of numbers to check in a variable
##start at 2 given the above note using the function's default argument
to_check <- c(first_prime:number)
##initatilize primes variable vector to store results into
primes <- NULL
count <- 0
##initatilize loop variable
loop <- first_prime
while (loop*loop < number) {
primes <- c(primes, to_check[1])
##remove multiples from to_check vector
to_check <- subset(to_check, !to_check %% loop == 0)
## update loop variable with next prime after multiples are removed
loop <- to_check[1]
count <- count+1
}
##given the loop stops "prematurely", concatenate remaining primes from to_check vector with primes storage vector
primes <- c(primes,to_check)
##can comment out these two print lines, for info only
print(paste("Loop executed ", count, " times"))
print(paste("Your number,", number, ", contains ", length(primes), " primes up to it and they are:"))
return(primes)
}
prime.sieve(17)
t.test <- function(data=c(), mu, pop.sd, two.tailed=TRUE, significance=.05) {
xbar <- mean(data)
n <- length(data)
z <- (xbar - mu) / (pop.sd /sqrt(n))
if (two.tailed==TRUE) {
p <- 2*pnorm(-abs(z))
} else {
p <- pnorm(-abs(z))
}
return(p)
}
x<-rnorm(n=10,2,2)
x
mean(x)
t.test(x,2,2)
t.test(x,2,2,FALSE)
### A demonstration of correlation and chi-square in R
### Preparation
setwd("/Users/gdc/Documents/MIDS/DATASCI_W203/Async Material and Sample Files /")
# car gives us nice scatterplots
library(car)
# We'll use our Country-by-Country dataset
load("Co")
summary(Countries)
# We'll also use Google's dataset of takedown requests -
# that is, orders that come from governments of
# different countries to remove certain content
# from Youtube, search results, and other online products.
# Each row of this dataset corresponds to a specific
# country and a specific online product (you can think
# of the unit of analysis as country x product), and there
# are several variables of interest:
#
# Country - the country making specific takedown requests
# Product - the online product the content is hosted on
#           (Youtube, Blogger, etc)
# Reason - a reason why the content is being targeted
#           (copyright violation, government criticism, etc..)
# Court.Orders - the number of requests from the Country's
#             court system
# Executive..Police..etc. - the number of requests from the
#             executive and other branches of government
# Items.Requested.To.Be.Removed - the number of separate items
#             of content.  However, this variable seems to
#             have a lot of missing values
# Read in the data
Requests = read.csv("Removal_Requests.csv")
head(Requests)
# Note that there are multiple rows per country in
# the Requests dataframe.
# Create a new variable for total number of requests from
# all branches of government
Requests$total.takedowns = Requests$Court.Orders + Requests$Executive..Police..etc.
# To merge our datasets, we first need to sum together all the
# rows for each country in the Requests dataset, so that
# each country only appears in one row.
# (we'll lose some variables when we do this, such as the product
# the request referred to)
R2 = aggregate(Requests[,c("Court.Orders", "Executive..Police..etc.", "total.takedowns")], list(Country = Requests$Country), sum)
# Notice that there's one row per country now.
head(R2)
# Perform the merge
Countries = merge(Countries, R2, by="Country", all=T)
head(Countries)
scatterplot(Countries$cpi, Countries$total.takedowns)
Countries = merge(Countries, R2, by="Country", all=T)
head(Countries)
summary(Countries)
load("Countries")
list.files()
load("Countries2")
load("Countries2.Rdata")
View(Countries)
summary(Countries)
# We'll also use Google's dataset of takedown requests -
# that is, orders that come from governments of
# different countries to remove certain content
# from Youtube, search results, and other online products.
# Each row of this dataset corresponds to a specific
# country and a specific online product (you can think
# of the unit of analysis as country x product), and there
# are several variables of interest:
#
# Country - the country making specific takedown requests
# Product - the online product the content is hosted on
#           (Youtube, Blogger, etc)
# Reason - a reason why the content is being targeted
#           (copyright violation, government criticism, etc..)
# Court.Orders - the number of requests from the Country's
#             court system
# Executive..Police..etc. - the number of requests from the
#             executive and other branches of government
# Items.Requested.To.Be.Removed - the number of separate items
#             of content.  However, this variable seems to
#             have a lot of missing values
# Read in the data
Requests = read.csv("Removal_Requests.csv")
head(Requests)
# Note that there are multiple rows per country in
# the Requests dataframe.
# Create a new variable for total number of requests from
# all branches of government
Requests$total.takedowns = Requests$Court.Orders + Requests$Executive..Police..etc.
# To merge our datasets, we first need to sum together all the
# rows for each country in the Requests dataset, so that
# each country only appears in one row.
# (we'll lose some variables when we do this, such as the product
# the request referred to)
R2 = aggregate(Requests[,c("Court.Orders", "Executive..Police..etc.", "total.takedowns")], list(Country = Requests$Country), sum)
# Notice that there's one row per country now.
head(R2)
# Perform the merge
Countries = merge(Countries, R2, by="Country", all=T)
head(Countries)
head(Countries)
head(R2)
Countries = merge(Countries, R2, by="Country", all=T)
head(Countries)
scatterplot(Countries$cpi, Countries$total.takedowns)
scatterplot(Countries$cpi, Countries$total.takedowns)
scatterplot(Countries$cpi, Countries$total.takedowns)
scatterplot(Countries$cpi, Countries$total.takedowns)
cor.test(Countries$cpi, Countries$total.takedowns)
setwd("/Users/gdc/Documents/MIDS/DATASCI_W203/Async Material and Sample Files /")
# car gives us nice scatterplots
library(car)
# We'll use our Country-by-Country dataset
load("Countries2.Rdata")
summary(Countries)
# We'll also use Google's dataset of takedown requests -
# that is, orders that come from governments of
# different countries to remove certain content
# from Youtube, search results, and other online products.
# Each row of this dataset corresponds to a specific
# country and a specific online product (you can think
# of the unit of analysis as country x product), and there
# are several variables of interest:
#
# Country - the country making specific takedown requests
# Product - the online product the content is hosted on
#           (Youtube, Blogger, etc)
# Reason - a reason why the content is being targeted
#           (copyright violation, government criticism, etc..)
# Court.Orders - the number of requests from the Country's
#             court system
# Executive..Police..etc. - the number of requests from the
#             executive and other branches of government
# Items.Requested.To.Be.Removed - the number of separate items
#             of content.  However, this variable seems to
#             have a lot of missing values
# Read in the data
Requests = read.csv("Removal_Requests.csv")
head(Requests)
# Note that there are multiple rows per country in
# the Requests dataframe.
# Create a new variable for total number of requests from
# all branches of government
Requests$total.takedowns = Requests$Court.Orders + Requests$Executive..Police..etc.
# To merge our datasets, we first need to sum together all the
# rows for each country in the Requests dataset, so that
# each country only appears in one row.
# (we'll lose some variables when we do this, such as the product
# the request referred to)
R2 = aggregate(Requests[,c("Court.Orders", "Executive..Police..etc.", "total.takedowns")], list(Country = Requests$Country), sum)
# Notice that there's one row per country now.
head(R2)
# Perform the merge
Countries = merge(Countries, R2, by="Country", all=T)
head(Countries)
scatterplot(Countries$cpi, Countries$total.takedowns)
cor.test(Countries$cpi, Countries$total.takedowns)
cor(Countries[,c("gdp", "cpi", "total.takedowns")], use = "pairwise.complete.obs")
cor(Countries[,c("gdp", "cpi", "total.takedowns")], use = "pairwise.complete.obs")**2
table(Countries$region, Countries$high_cpi)
cs = chisq.test(Countries$region, Countries$high_cpi)
cs = chisq.test(Countries$region, Countries$high_cpi)
cs$stdres
cs
names(cs)
cs$expected
table(Countries$region, Countries$high_cpi)
cramers_v = function(cs)
{
cv = sqrt(cs$statistic / (sum(cs$observed) * (min(dim(cs$observed))-1)))
print.noquote("Cramer's V:")
return(as.numeric(cv))
}
cramers_v(cs)
Corrupt_Source = aggregate(Countries[,c("Court.Orders", "Executive..Police..etc.")], list(high_cpi = Countries$high_cpi), sum, na.rm=T)
rownames(Corrupt_Source)=Corrupt_Source$high_cpi
Corrupt_Source
cs = chisq.test(Corrupt_Source[,c(-1)])
cs
corrupt_odds = Corrupt_Source["Corrupt","Court.Orders"] / Corrupt_Source["Corrupt","Executive..Police..etc."]
trustworthy_odds = Corrupt_Source["Trustworthy","Court.Orders"] / Corrupt_Source["Trustworthy","Executive..Police..etc."]
corrupt_odds / trustworthy_odds
Requests2 = merge(Countries[,c("Country", "high_cpi")], Requests, by="Country")
Requests2 = Requests2[ ! is.na(Requests2$high_cpi),]
head(Requests2)
View(head(Requests2))
Corrupt_Product = Requests2[,c("Product","high_cpi")]
Corrupt_Product$Corrupt = ifelse(Requests2$high_cpi == "Corrupt", Requests2$total.takedowns, 0)
View(Corrupt_Product)
Corrupt_Product$Trustworthy = ifelse(Requests2$high_cpi == "Trustworthy", Requests2$total.takedowns, 0)
head(Corrupt_Product)
Corrupt_Product =  aggregate(Corrupt_Product[,c("Corrupt","Trustworthy")], list( Product = Corrupt_Product$Product), sum)
Corrupt_Product
library(reshape)
install.packages("reshape")
?reshape
??library(reshape)
?library(reshape)
library(reshape)
Corrupt_Product = cast(Requests2, Product ~ high_cpi , fun = sum, value = c("total.takedowns"))
Corrupt_Product
cs = chisq.test(Corrupt_Product[,c(-1)])
cs
getwd()
load("Countries3.Rdata")
summary(Countries)
ls()
rm( list = ls() )
load("Countries3.Rdata")
summary(Countries)
describe(Countries)
library(psych)
describe(Countries)
View(describe(Countries))
summary(Countries)
summary(Countries$)
Countries$loggdp = log10(Countries$gdp)
by(Countries$loggdp, Countries$high_cpi, mean, na.rm = TRUE)
?by
qqnorm(Countries$loggdp)
shapiro.test(Countries$loggdp)
t.test(Countries$loggdp ~ Countries$high_cpi, Countries)
cohens_d <- function(x, y) {
# this function takes two vectors as inputs, and compares
# their means
# first, compute the pooled standard error
lx = length(subset(x,!is.na(x)))
ly = length(subset(y,!is.na(y)))
# numerator of the pooled variance:
num = (lx-1)*var(x, na.rm=T) + (ly-1)*var(y, na.rm=T)
pooled_var = num / (lx + ly - 2) # variance
pooled_sd = sqrt(pooled_var)
# finally, compute cohen's d
cd = abs(mean(x, na.rm=T) - mean(y, na.rm=T)) / pooled_sd
return(cd)
}
loggdp_c = Countries$loggdp[Countries$high_cpi=="Corrupt"]
loggdp_t = Countries$loggdp[Countries$high_cpi=="Trustworthy"]
cohens_d(loggdp_c, loggdp_t)
cor.test(Countries$loggdp, as.numeric(factor(Countries$high_cpi)))
Americas = Countries[Countries$region == "Americas",]
summary(Americas)
by(Americas$total.takedowns, Americas$high_cpi, mean, na.rm = TRUE)
qqnorm(Americas$total.takedowns)
wilcox.test(Americas$total.takedowns ~ Americas$high_cpi)
takedowns_c = Americas$total.takedowns[Americas$high_cpi == "Corrupt"]
takedowns_t = Americas$total.takedowns[Americas$high_cpi == "Trustworthy"]
cohens_d(takedowns_c, takedowns_t)
mean(Countries$Court.Orders, na.rm = T)
mean(Countries$Executive, na.rm = T)
t.test(Countries$Court.Orders, Countries$Executive, paired = T)
# effect size
cohens_d(Countries$Court.Orders, Countries$Executive)
